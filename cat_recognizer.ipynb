{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction\n",
    "The purpose of this notebook is to quickly train a image classifier that is able to distinguish between images of cats and dogs and achieve some acceptable degree of performance (a binary classification problem). Accuracy will be used to evaluate the performance and we'll train a simple CNN to classify the images.\n",
    "\n",
    "In order to make this notebook neat, some helper functions are defined in the [utils.py](utils.py), feel free to check it out when you want to dig deeper."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from utils import *\n",
    "from settings import TRAIN_DIR, TEST_DIR, TRAIN_X_MEAN_NPY, TRAIN_X_STD_NPY, LOG_DIR, SAVE_PATH\n",
    "%matplotlib inline\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset preparation\n",
    "The image data we're going to use is [Dogs vs. Cats](https://www.kaggle.com/c/dogs-vs-cats/data) dataset available on [Kaggle](https://www.kaggle.com/) which contain 25,000 images of dogs and cats. You may need a Kaggle account to download the dataset on your local machine. The training set and test set  will be stored under ```datasets/train``` and ```datasets/test1``` subdirectories respectively. To make the whole training process reproducable, we first set random seeds of TensorFlow and Numpy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.set_random_seed(94)\n",
    "np.random.seed(87)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "keep_output": true
   },
   "outputs": [],
   "source": [
    "print(\"Number of training images: {}\".format(len(glob.glob(os.path.join(TRAIN_DIR, '*.jpg')))))\n",
    "print(\"Number of test images: {}\".format(len(glob.glob(os.path.join(TEST_DIR, '*.jpg')))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load the dataset and resize the images\n",
    "The dataset will include two parts:\n",
    "- X: the actual images transformed to ndarray with shape of ```(#images, height, width, #channels)```\n",
    "- y: corresponding labels, where ```label = 0``` for dog images and ```label = 1``` for cat images.\n",
    "\n",
    "There are 25,000 images in total available for training. We will shuffle the whole dataset, use all of them, 20,000 of which training and 5,000 validation, and resize the images' height and width to [64, 64] to make our model simpler."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_size = 64\n",
    "dataset_size = len(glob.glob(os.path.join(TRAIN_DIR, '*.jpg')))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will save the resized images and labels as `features.npy` and `targets.npy` in the directory `datasets/train/` when the images are loaded first time. It will become faster when you reload the dataset again."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "X, y = load_image_dataset(size=(image_size, image_size))\n",
    "perm = np.random.permutation(dataset_size)\n",
    "X, y = X[perm], y[perm]  # X is only shuffled along it's first index.\n",
    "print(X.shape, y.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Inspect images in the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "keep_output": true
   },
   "outputs": [],
   "source": [
    "num_samples = 5\n",
    "show_images_horizontally(X[:num_samples], y[:num_samples], figsize=(15, 10),\n",
    "                         lookup_label={0: 'Dog', 1: 'Cat'})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Build training / validation set\n",
    "It's a good practice to make a subset of dataset as validation set and tuning our models before actually test their performance on the test set. The dataset has already been shuffled, so we only have to seperate it into training set / validation set in the ratio of (0.9, 0.1)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set_ratio = 0.9\n",
    "idx = int(dataset_size * train_set_ratio)\n",
    "valid_set_size = X.shape[0] - idx\n",
    "train_X, train_y, valid_X, valid_y = X[:idx], y[:idx], X[idx:], y[idx:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "keep_output": true
   },
   "outputs": [],
   "source": [
    "print('Training set: {}, {}'.format(train_X.shape, train_y.shape))\n",
    "print('Validation set: {}, {}'.format(valid_X.shape, valid_y.shape))\n",
    "print('Some images in validation set:')\n",
    "show_images_horizontally(valid_X[:num_samples], valid_y[:num_samples], figsize=(15, 10),\n",
    "                         lookup_label={0: 'Dog', 1: 'Cat'})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Normalization\n",
    "To represent color images, the red, green and blue channels (RGB) must be specified for each pixel, and so the pixel value is actually a vector of three numbers ranging from 0 to 255.\n",
    "\n",
    "One common preprocessing step in machine learning is to **center and standardize** your dataset, meaning that you substract the mean of the whole numpy array from each example, and then divide each example by the standard deviation of the whole numpy array. Note that validation data are only for validation use, so we can pretend that we have \"seen\" the validation data. Not letting validation data polluting the training process (also known as **data leak** problem), we use only training data's mean and std to normalize the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "train_X, valid_X = train_X.astype(np.float32), valid_X.astype(np.float32)\n",
    "train_X_mean, train_X_std = train_X.mean(), train_X.std()\n",
    "np.save(TRAIN_X_MEAN_NPY, train_X_mean)\n",
    "np.save(TRAIN_X_STD_NPY, train_X_std)\n",
    "train_X = (train_X - train_X_mean) / train_X_std\n",
    "valid_X = (valid_X - train_X_mean) / train_X_std  # Use train_X's mean and std to normalize valid_X.\n",
    "show_images_horizontally((valid_X[:num_samples] * train_X_std + train_X_mean).astype(np.uint8), valid_y[:num_samples], figsize=(15, 10),\n",
    "                         lookup_label={0: 'Dog', 1: 'Cat'})\n",
    "print(valid_X.mean(), valid_X.std())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that the validation data's mean is close to 0 and std close to 1, which is good."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### Class distribution in dataset\n",
    "Make sure the distribution of training/validation set are similar and there is no serious unbalanced class problem. In this dataset, there are only two classes: cats and dogs, so it will be prefect that the dataset consist of about 50% of dogs and cats, respectively."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_cat, valid_cat = train_y == 1, valid_y == 1\n",
    "print('{:.1f}% images in training set are cats'.format(len(train_y[train_cat]) / len(train_y) * 100))\n",
    "print('{:.1f}% images in validation set are cats'.format(len(valid_y[valid_cat]) / len(valid_y) * 100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Seems that we're good to go."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build the classifier\n",
    "For the binary classification we're facing (for any image, whether it's a cat image or dog image), we will use a simple convoluational neural network with two convolational layers followed by a fully connected layer. In terms of regularization, we will use dropout between conv and fully-connected layer."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hyper parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 64\n",
    "patch_size = 5\n",
    "input_depth = 3\n",
    "output_depth = 16\n",
    "num_hidden = 16\n",
    "keep_prob = 0.5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluation metric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy(predictions, labels):\n",
    "    return (100.0 * np.sum((predictions > 0.5).astype(float) == labels)\\\n",
    "            / predictions.shape[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define layer templates for model\n",
    "We will define all related stuffs (weights, bias, relu) in the `tf.name_scope`and use `tf.summary` op to save graph data for both convoluational layer and fully-connected layer respectively. This will enable tensorboard to visualize our model later."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convolutional layer\n",
    "def conv_layer(input, patch_size, input_depth, output_depth, name=\"conv\", params=None):\n",
    "    with tf.name_scope(name):\n",
    "        w_name = '.'.join((name, 'w'))\n",
    "        b_name = '.'.join((name, 'b'))\n",
    "        \n",
    "        if params and params[w_name]:\n",
    "            w = params[w_name]\n",
    "            b = params[b_name]\n",
    "        else:\n",
    "            w = tf.Variable(\n",
    "                tf.truncated_normal([patch_size, patch_size, input_depth, output_depth], stddev=0.1), name=\"Weights\")\n",
    "            b = tf.Variable(tf.constant(0.1, shape=[output_depth]), name=\"Biases\")\n",
    "            params[w_name] = w\n",
    "            params[b_name] = b\n",
    "        \n",
    "#         conv = tf.nn.conv2d(input, w, strides=[1, 1, 1, 1], padding=\"SAME\")\n",
    "        conv = tf.nn.conv2d(input, w, strides=[1, 2, 2, 1], padding=\"SAME\")\n",
    "        act = tf.nn.relu(conv + b)\n",
    "        tf.summary.histogram(\"weights\", w)\n",
    "        tf.summary.histogram(\"biases\", b)\n",
    "        tf.summary.histogram(\"activations\", act)\n",
    "#         pool = tf.nn.max_pool(act, ksize=[1, 2, 2, 1], strides=[1, 2, 2, 1], padding=\"SAME\")\n",
    "\n",
    "\n",
    "        return act\n",
    "\n",
    "# fully-connected layer\n",
    "def fc_layer(input, size_in, size_out, name=\"fc\", params=None):\n",
    "    with tf.name_scope(name):\n",
    "        w_name = '.'.join((name, 'w'))\n",
    "        b_name = '.'.join((name, 'b'))\n",
    "        \n",
    "        if params and params[w_name]:\n",
    "            w = params[w_name]\n",
    "            b = params[b_name]\n",
    "        else:\n",
    "            w = tf.Variable(tf.truncated_normal([size_in, size_out], stddev=0.1), name=\"Weights\")\n",
    "            b = tf.Variable(tf.constant(0.1, shape=[size_out]), name=\"Biases\")\n",
    "            params[w_name] = w\n",
    "            params[b_name] = b\n",
    "        \n",
    "        act = tf.matmul(input, w) + b\n",
    "        tf.summary.histogram(\"weights\", w)\n",
    "        tf.summary.histogram(\"biases\", b)\n",
    "        tf.summary.histogram(\"activations\", act)\n",
    "        return act"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Computation graph\n",
    "After instruct our model how to do forward prop, TensorFlow will do the back prop for us automatically.\n",
    "Some tips here:\n",
    "- make sure to name every tensor for easier reference later\n",
    "- create tensors designed for single image prediction: ```tf_new_X``` and ```tf_new_y```\n",
    "- set keep_prob of dropout to 1 when making prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "graph = tf.Graph()\n",
    "\n",
    "with graph.as_default():\n",
    "    # input of every mini-batch training data\n",
    "    tf_train_X = tf.placeholder(tf.float32, name='tf_train_X',\n",
    "        shape=(batch_size, image_size, image_size, input_depth))\n",
    "    tf_train_y = tf.placeholder(tf.float32, name='tf_train_y', \n",
    "        shape=(batch_size, 1))\n",
    "    \n",
    "    # show some images in tensorboard\n",
    "    tf.summary.image('training_images', tf_train_X, 16)\n",
    "    \n",
    "    # input for every single realtime prediction\n",
    "    tf_new_X = tf.placeholder(tf.float32, name='tf_new_X',\n",
    "        shape=(1, image_size, image_size, input_depth))\n",
    "    tf_new_y = tf.placeholder(tf.float32, name='tf_new_y',\n",
    "        shape=[1, 1])\n",
    "    \n",
    "    # use entire validation set to evaluate model\n",
    "    tf_valid_X = tf.constant(valid_X.astype('float32'),\n",
    "        name='tf_valid_X')\n",
    "    tf_valid_y = tf.constant(valid_y.astype('float32'), name='tf_valid_y')\n",
    "    \n",
    "    # turn off dropout regularization when predict and allow\n",
    "    # adjustment when training\n",
    "    tf_keep_prob_train = tf.placeholder_with_default(1.0, \n",
    "        name='tf_keep_prob_train', shape=())\n",
    "    tf_keep_prob_valid = tf.constant(1.0, name='tf_keep_prob_valid',\n",
    "        shape=())\n",
    "\n",
    "    params = {\n",
    "        'conv1.w': None, 'conv1.b': None,\n",
    "        'conv2.w': None, 'conv2.b': None,\n",
    "        'fc1.w': None, 'fc1.b': None,\n",
    "        'fc2.w': None, 'fc2.b': None\n",
    "    }\n",
    "    \n",
    "    \n",
    "    # create the network\n",
    "    def model(data, keep_prob, params):\n",
    "        conv1 = conv_layer(\n",
    "            data, patch_size, input_depth, output_depth, 'conv1', params)\n",
    "        conv2 = conv_layer(\n",
    "            conv1, patch_size, output_depth, output_depth, 'conv2', params)\n",
    "        shape = conv2.get_shape().as_list()\n",
    "        flattened = tf.reshape(conv2,\n",
    "            [-1, shape[1] * shape[2] * shape[3]])\n",
    "        \n",
    "        dropout = tf.nn.dropout(flattened, keep_prob)\n",
    "        fc1 = fc_layer(dropout,\n",
    "            image_size // 4 * image_size // 4 * output_depth,\n",
    "            num_hidden, 'fc1', params)\n",
    "        with tf.name_scope('relu'):\n",
    "            hidden_act = tf.nn.relu(fc1)\n",
    "        \n",
    "        return fc_layer(hidden_act, num_hidden, 1, 'fc2', params)\n",
    "    \n",
    "    \n",
    "    # Training computation.\n",
    "    logits = model(tf_train_X, tf_keep_prob_train, params)\n",
    "    with tf.name_scope('loss'):\n",
    "        loss = tf.reduce_mean(\n",
    "            tf.nn.sigmoid_cross_entropy_with_logits(\n",
    "                labels=tf_train_y, logits=logits), name='loss')\n",
    "        tf.summary.scalar(\"cross_entropy\", loss)\n",
    "\n",
    "    # Optimizer.\n",
    "    with tf.name_scope('train'):\n",
    "        optimizer = tf.train.GradientDescentOptimizer(0.05).minimize(loss)\n",
    "    \n",
    "    # Predictions for the training, validation set and new image\n",
    "    tf_train_y_pred = tf.nn.sigmoid(logits, name='tf_train_y_pred')\n",
    "    tf_valid_y_pred = tf.nn.sigmoid(\n",
    "        model(tf_valid_X, tf_keep_prob_valid, params), name='tf_valid_y_pred')\n",
    "    tf_new_y_pred = tf.nn.sigmoid(\n",
    "        model(tf_new_X, tf_keep_prob_valid, params), name='tf_new_y_pred')\n",
    "    \n",
    "    \n",
    "    with tf.name_scope(\"evaluation\"):\n",
    "        def acc(pred, label):\n",
    "            sh = label.shape\n",
    "            return tf.reduce_sum(tf.cast(tf.equal(tf.where(\n",
    "                pred > 0.5, tf.ones(sh), tf.zeros(sh)), label), tf.int32)) / sh[0]\n",
    "        \n",
    "        train_acc = acc(tf_train_y_pred, tf_train_y)\n",
    "        valid_acc = acc(tf_valid_y_pred, tf_valid_y)\n",
    "        tf.summary.scalar(\"batch_accuracy\", train_acc)\n",
    "        tf.summary.scalar(\"valid_accuracy\", valid_acc)\n",
    "    \n",
    "    # Add ops to save and restore all the variables.\n",
    "    saver = tf.train.Saver()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train and serialize model\n",
    "We will use mini-batch GD to train our model. After finish training, save the trained model for later usage.\n",
    "\n",
    "Tips:\n",
    "- set keep_prob of dropout regularization to 0.5 when training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "num_steps = 140625  # 400 epochs\n",
    "step_interval = 500\n",
    "\n",
    "with tf.Session(graph=graph) as sess:\n",
    "    tf.global_variables_initializer().run()\n",
    "#     tf.local_variables_initializer().run() # for init 'total' in tf.metrics.accuracy\n",
    "    \n",
    "    # write to log for tensorboard\n",
    "    merged_summary = tf.summary.merge_all()\n",
    "    writer = tf.summary.FileWriter(LOG_DIR)\n",
    "    writer.add_graph(sess.graph)\n",
    "    \n",
    "    \n",
    "    for step in range(num_steps):\n",
    "        # get new mini-batch for training\n",
    "        offset = (step * batch_size) % (train_y.shape[0] - batch_size)\n",
    "        batch_X = train_X[offset:(offset + batch_size), :, :, :]\n",
    "        batch_y = train_y[offset:(offset + batch_size), :]\n",
    "        \n",
    "        # enable dropout regularization when training\n",
    "        feed_dict = {\n",
    "            tf_train_X: batch_X,\n",
    "            tf_train_y: batch_y,\n",
    "            tf_keep_prob_train: 0.5,\n",
    "            tf_new_X: batch_X[:1]\n",
    "        }\n",
    "        _, l, batch_y_pred = sess.run(\n",
    "            [optimizer, loss, tf_train_y_pred], feed_dict=feed_dict)\n",
    "        \n",
    "\n",
    "        # write summary\n",
    "        if (step % 100 == 0):\n",
    "            s = sess.run(merged_summary, feed_dict=feed_dict)\n",
    "            writer.add_summary(s, step)\n",
    "        \n",
    "        # output loss and accuracy while training\n",
    "        if (step % step_interval == 0):\n",
    "            print('Minibatch loss at step {}: {:.3f}, '.format(step, l) +\n",
    "                  'batch acc: {:.1f}%, Valid acc: {:.1f}%.'\\\n",
    "                  .format(accuracy(batch_y_pred, batch_y),\n",
    "                          accuracy(tf_valid_y_pred.eval(), valid_y)))\n",
    "            \n",
    "    # final prediction for validation set\n",
    "    vaild_y_pred_before_restore = tf_valid_y_pred.eval()\n",
    "    \n",
    "    \n",
    "    # Save the variables to disk.\n",
    "    save_path = saver.save(sess, SAVE_PATH)\n",
    "    print(\"Model saved in file: %s\" % SAVE_PATH)\n",
    "    \n",
    "    writer.flush()\n",
    "    writer.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Although the performance can be further improved, as our goal is to train a simple model and deploy it, we will just leave it here and take a look where did the model make the mistake on validation set.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Show some mis-classified images"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get indices of mis-classified images in validation set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mislabeled_indices = []\n",
    "for idx, (i, j) in enumerate(zip(vaild_y_pred_before_restore.reshape(-1, 1), valid_y.reshape(-1, 1))):\n",
    "    prob, label = i[0], j[0]\n",
    "    label_pred = 1 if prob > 0.5 else 0\n",
    "    if label_pred != label: mislabeled_indices.append(idx)\n",
    "print('{}% of images are mis-classified in validation set.'\\\n",
    "      .format(len(mislabeled_indices) / valid_y.shape[0] * 100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "samples = np.random.choice(mislabeled_indices, 5)\n",
    "show_images_horizontally((valid_X[samples] * train_X_std + train_X_mean).astype(np.uint8), valid_y[samples], figsize=(15, 10),\n",
    "                         lookup_label={0: 'Pred: Cat', 1: 'Pred: Dog'})\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Real time prediction simulation\n",
    "Upon now, we already trained a model that is ready to be deploy! Let's load the model we saved earlier and see whether we can generate the same prediction result on validation set using the loaded model.\n",
    "\n",
    "If there is any error in this part, try to restart kernel and run all the code again.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "meta_path = 'models/model.ckpt.meta'\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load the model and make prediction on validation set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Later, launch the model, use the saver to restore variables from disk, and\n",
    "# do some work with the model.\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    \n",
    "    # Restore variables from disk.\n",
    "    new_saver = tf.train.import_meta_graph(meta_path)\n",
    "    new_saver.restore(sess, save_path)\n",
    "    print(\"Model restored.\")\n",
    "    \n",
    "    #Now, access the op that you want to run. \n",
    "    graph = tf.get_default_graph()\n",
    "    tf_new_X = graph.get_tensor_by_name(\"tf_new_X:0\")\n",
    "    tf_new_y = graph.get_tensor_by_name(\"tf_new_y:0\")\n",
    "    tf_new_y_pred = graph.get_tensor_by_name(\"tf_new_y_pred:0\")\n",
    "\n",
    "    feed_dict = {\n",
    "        tf_new_X: valid_X[:1],\n",
    "        tf_new_y: valid_y[:1]\n",
    "    }\n",
    "\n",
    "    new_y_pred = sess.run(\n",
    "            [tf_new_y_pred], feed_dict=feed_dict)\n",
    "    \n",
    "    tf_valid_y_pred = graph.get_tensor_by_name(\"tf_valid_y_pred:0\")\n",
    "\n",
    "    vaild_y_pred_after_restore = tf_valid_y_pred.eval()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sanity check \n",
    "Compare prediction result on validation before/after model restoration to make sure we got the right model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if np.all(vaild_y_pred_before_restore==vaild_y_pred_after_restore):\n",
    "    print(\"Loaded model's prediction on validation is exactly the same as expected.\")\n",
    "else:\n",
    "    print(\"Loaded model's prediction on validation is different; something is wrong.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary\n",
    "In next step, we will deploy this model and try to build a ML application."
   ]
  }
 ],
 "metadata": {
  "gist": {
   "data": {
    "description": "cat_recognizer.ipynb",
    "public": true
   },
   "id": ""
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  },
  "toc": {
   "nav_menu": {
    "height": "265px",
    "width": "390px"
   },
   "number_sections": false,
   "sideBar": false,
   "skip_h1_title": false,
   "toc_cell": false,
   "toc_position": {
    "height": "89px",
    "left": "1018.23px",
    "right": "20px",
    "top": "120px",
    "width": "225px"
   },
   "toc_section_display": "none",
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "oldHeight": 297,
   "position": {
    "height": "319px",
    "left": "1091px",
    "right": "20px",
    "top": "132px",
    "width": "336px"
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "varInspector_section_display": "block",
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
