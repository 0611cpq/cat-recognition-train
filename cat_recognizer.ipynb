{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction\n",
    "The purpose of this notebook is to quickly train a image classifier that is able to distinguish between images of cats and dogs and achieve some acceptable degree of performance (a binary classification problem). Accuracy will be used to evaluate the performance and we'll train a simple CNN to classify the images.\n",
    "\n",
    "In order to make this notebook neat, some helper functions are defined in the [utils.py](utils.py), feel free to check it out when you want to dig deeper."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import tensorflow as tf\n",
    "from utils import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "jupyter notebook magic functions \n",
    "- render graph directly without ```plt.show()```\n",
    "- to reload the external python script whenever there are changes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "%reload_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset preparation\n",
    "The image data we're going to use is [Dogs vs. Cats](https://www.kaggle.com/c/dogs-vs-cats/data) dataset available on [Kaggle](https://www.kaggle.com/) which contain 25,000 images of dogs and cats. You may need a Kaggle account to download the dataset on your local machine. The training set and test set  will be stored under ```datasets/train``` and ```datasets/test1``` subdirectories respectively."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TRAIN_DIR = 'datasets/train/'\n",
    "TEST_DIR = 'datasets/test1'\n",
    "print(\"Number of training images: {}\".format(len(os.listdir(TRAIN_DIR))))\n",
    "print(\"Number of test images: {}\".format(len(os.listdir(TEST_DIR))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load the dataset and resize the images\n",
    "The dataset will include two parts:\n",
    "- X: the actual images transformed to ndarray with shape of ```(#images, height, width, #channels)```\n",
    "- y: corresponding labels, where ```label = 0``` for dog images and ```label = 1``` for cat images.\n",
    "\n",
    "Notice that there are 25,000 images in total available for training, but we will just use a subset of it like 5,000 images to speed up training phase. Also resize the images' height and width to 64."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_size = 1000\n",
    "image_size = 64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "X, y = load_image_dataset(dataset_size=dataset_size, size=(image_size, image_size))\n",
    "print(X.shape, y.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Inspect images in the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_samples = 5\n",
    "show_images_horizontally(X[:num_samples], y[:num_samples], figsize=(15, 10),\n",
    "                         lookup_label={0: 'Dog', 1: 'Cat'})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Normalization\n",
    "To represent color images, the red, green and blue channels (RGB) must be specified for each pixel, and so the pixel value is actually a vector of three numbers ranging from 0 to 255.\n",
    "\n",
    "One common preprocessing step in machine learning is to **center and standardize** your dataset, meaning that you substract the mean of the whole numpy array from each example, and then divide each example by the standard deviation of the whole numpy array. But for **picture** datasets, it is simpler and more convenient and works almost as well to just divide every row of the dataset by 255 (the maximum value of a pixel channel)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "X = X / 255"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Although there seems no difference in human eyes after normlization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_samples = 5\n",
    "show_images_horizontally(X[:num_samples], y[:num_samples], figsize=(15, 10),\n",
    "                         lookup_label={0: 'Dog', 1: 'Cat'})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Build training / validation set\n",
    "It's a good practice to make a subset of dataset as validation set and tuning our models before actually test their performance on the test set. Because the order of images in the dataset are already randomized (by randomly pick images in the folder), we can just separate the dataset into training set / validation set in the ratio of (0.9, 0.1) without further shuffling."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set_ratio = 0.9\n",
    "threshold = 500\n",
    "idx = int(dataset_size * train_set_ratio)\n",
    "valid_set_size = X.shape[0] - idx\n",
    "idx = X.shape[0] - threshold if valid_set_size > threshold else idx\n",
    "train_X, train_y, valid_X, valid_y = X[:idx], y[:idx], X[idx:], y[idx:]\n",
    "# del X, y # tips to save memory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Training set: {}, {}'.format(train_X.shape, train_y.shape))\n",
    "print('Validation set: {}, {}'.format(valid_X.shape, valid_y.shape))\n",
    "print('Some images in validation set:')\n",
    "show_images_horizontally(valid_X[:num_samples], valid_y[:num_samples], figsize=(15, 10),\n",
    "                         lookup_label={0: 'Dog', 1: 'Cat'})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Class distribution in dataset\n",
    "Make sure the distribution of training/validation set are similar and there is no serious unbalanced class problem. In this dataset, there are only two classes: cats and dogs, so it will be prefect that the dataset consist of about 50% of dogs and cats, respectively."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_cat, valid_cat = train_y == 1, valid_y == 1\n",
    "print('{:.1f}% images in training set are cats'.format(len(train_y[train_cat]) / len(train_y) * 100))\n",
    "print('{:.1f}% images in validation set are cats'.format(len(valid_y[valid_cat]) / len(valid_y) * 100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Seems that we're good to go."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build the classifier\n",
    "For the binary classification we're facing (for any image, whether it's a cat image or dog image), we will use a simple convoluational neural network with two convolational layers followed by a fully connected layer. In terms of regularization, we will use dropout between conv and fully-connected layer."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hyper parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 16\n",
    "patch_size = 5\n",
    "input_depth = 3\n",
    "output_depth = 16\n",
    "num_hidden = 16\n",
    "keep_prob = 0.5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define evaluation metric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy(predictions, labels):\n",
    "    return (100.0 * np.sum((predictions > 0.5).astype(float) == labels)\\\n",
    "            / predictions.shape[0])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Computation graph\n",
    "After instruct our model how to do forward prop, TensorFlow will do the back prop for us automatically.\n",
    "Some tips here:\n",
    "- make sure to name every tensor for easier reference later\n",
    "- create tensors designed for single image prediction: ```tf_new_X``` and ```tf_new_y```\n",
    "- set keep_prob of dropout to 1 when making prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "graph = tf.Graph()\n",
    "\n",
    "with graph.as_default():\n",
    "    # input of every mini-batch training data\n",
    "    tf_train_X = tf.placeholder(tf.float32, name='tf_train_X',\n",
    "        shape=(batch_size, image_size, image_size, input_depth))\n",
    "    tf_train_y = tf.placeholder(tf.float32, name='tf_train_y', \n",
    "        shape=(batch_size, 1))\n",
    "    \n",
    "    # input for every single realtime prediction\n",
    "    tf_new_X = tf.placeholder(tf.float32, name='tf_new_X',\n",
    "        shape=(1, image_size, image_size, input_depth))\n",
    "    tf_new_y = tf.placeholder(tf.float32, name='tf_new_y',\n",
    "        shape=(1, 1))\n",
    "    \n",
    "    # use entire validation set to evaluate model\n",
    "    tf_valid_X = tf.constant(valid_X.astype('float32'),\n",
    "        name='tf_valid_X')\n",
    "    \n",
    "    # turn off dropout regularization when predict and allow\n",
    "    # adjustment when training\n",
    "    tf_keep_prob = tf.placeholder_with_default(1.0, name='tf_keep_prob',\n",
    "        shape=())\n",
    "\n",
    "    # define parameters(weights / biases) when init: \n",
    "    # When defining weights for a convoluational layer, use the notation\n",
    "    # [filter_size, filter_size, input_depth, output_depth]\n",
    "    layer1_weights = tf.Variable(\n",
    "        tf.truncated_normal(\n",
    "            [patch_size, patch_size, input_depth, output_depth], stddev=0.1))\n",
    "    print(layer1_weights)\n",
    "    layer1_biases = tf.Variable(tf.zeros([output_depth]))\n",
    "    print(layer1_biases)\n",
    "    \n",
    "    # in this CNN, two convoluational layers happen to have the same depth.\n",
    "    # if we want, we can adjust them to be different like depth1, depth2\n",
    "    layer2_weights = tf.Variable(\n",
    "        tf.truncated_normal(\n",
    "            [patch_size, patch_size, output_depth, output_depth], stddev=0.1))\n",
    "    print(layer2_weights)\n",
    "    layer2_biases = tf.Variable(tf.constant(1.0, shape=[output_depth]))\n",
    "    \n",
    "    \n",
    "    # because we use stride = 2 and SAME padding, our new shape of first feature map C1\n",
    "    # will be (image_size // 2, image_size //2). and because we use 2 convolutional layers,\n",
    "    # the shape of second feature map C2 will be (image_size // 2 // 2, image_size // 2 // 2)\n",
    "    # = (image_size // 4, image_size // 4). and because we have output_depth == 16,\n",
    "    # the total neurons on C2 will be image_size // 4 * image_size // 4 * depth\n",
    "    layer3_weights = tf.Variable(\n",
    "        tf.truncated_normal(\n",
    "            [image_size // 4 * image_size // 4 * output_depth, num_hidden],\n",
    "            stddev=0.1))\n",
    "    layer3_biases = tf.Variable(tf.constant(1.0, shape=[num_hidden]))\n",
    "    layer4_weights = tf.Variable(\n",
    "        tf.truncated_normal([num_hidden, 1], stddev=0.1))\n",
    "    layer4_biases = tf.Variable(tf.constant(1.0, shape=[1]))\n",
    "\n",
    "    # Model.\n",
    "    def model(data):\n",
    "        # this is where we set stride = 2 for both width and height and also SAME padding\n",
    "        # the third parameters in tf.nn.conv2d is to set stride for every dimension\n",
    "        # specified in the first parameter data's shape\n",
    "        conv = tf.nn.conv2d(data, layer1_weights, [1, 2, 2, 1], padding='SAME')\n",
    "        hidden = tf.nn.relu(conv + layer1_biases)\n",
    "        conv = tf.nn.conv2d(\n",
    "            hidden, layer2_weights, [1, 2, 2, 1], padding='SAME')\n",
    "        hidden = tf.nn.relu(conv + layer2_biases)\n",
    "        shape = hidden.get_shape().as_list()\n",
    "        \n",
    "        # turn the C2 3D cube back to 2D matrix by shape (#data_points, #neurons)\n",
    "        reshape = tf.reshape(hidden,\n",
    "            [shape[0], shape[1] * shape[2] * shape[3]])\n",
    "#         dropout = tf.nn.dropout(reshape, tf_keep_prob)\n",
    "#         hidden = tf.nn.relu(tf.matmul(dropout, layer3_weights) + layer3_biases)\n",
    "        hidden = tf.nn.relu(tf.matmul(reshape, layer3_weights) + layer3_biases)\n",
    "        return tf.matmul(hidden, layer4_weights) + layer4_biases\n",
    "\n",
    "    # Training computation.\n",
    "    logits = model(tf_train_X)\n",
    "    loss = tf.reduce_mean(\n",
    "        tf.nn.sigmoid_cross_entropy_with_logits(\n",
    "            labels=tf_train_y, logits=logits), name='loss')\n",
    "\n",
    "    # Optimizer.\n",
    "    optimizer = tf.train.GradientDescentOptimizer(0.05).minimize(loss)\n",
    "    \n",
    "    # Predictions for the training, validation set and realtime prediction\n",
    "    tf_train_y_pred = tf.nn.sigmoid(logits, name='tf_train_y_pred')\n",
    "    tf_valid_y_pred = tf.nn.sigmoid(model(tf_valid_X), name='tf_valid_y_pred')\n",
    "    tf_new_y_pred = tf.nn.sigmoid(model(tf_new_X), name='tf_new_y_pred')\n",
    "    print(tf_new_y_pred, tf_valid_y_pred )\n",
    "    \n",
    "    # Add ops to save and restore all the variables.\n",
    "    saver = tf.train.Saver()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train and serialize model\n",
    "We will use mini-batch GD to train our model. After finish training, save the trained model for later usage.\n",
    "Tips:\n",
    "- set keep_prob of dropout regularization to 0.5 when training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_path = 'models/model.ckpt'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "num_steps = 1001\n",
    "step_interval = 500\n",
    "\n",
    "with tf.Session(graph=graph) as sess:\n",
    "    # initialize weights\n",
    "    tf.global_variables_initializer().run()\n",
    "    \n",
    "    for step in range(num_steps):\n",
    "        # get new mini-batch for training\n",
    "        offset = (step * batch_size) % (train_y.shape[0] - batch_size)\n",
    "        batch_X = train_X[offset:(offset + batch_size), :, :, :]\n",
    "        batch_y = train_y[offset:(offset + batch_size), :]\n",
    "        \n",
    "        # enable dropout regularization when training\n",
    "        feed_dict = {\n",
    "            tf_train_X: batch_X,\n",
    "            tf_train_y: batch_y,\n",
    "            tf_keep_prob: keep_prob\n",
    "        }\n",
    "        _, l, batch_y_pred = sess.run(\n",
    "            [optimizer, loss, tf_train_y_pred], feed_dict=feed_dict)\n",
    "        \n",
    "        # output loss and accuracy while training\n",
    "        if (step % step_interval == 0):\n",
    "            print('Minibatch loss at step {}: {:.3f}.'.format(step, l) +\n",
    "                  'batch acc: {:.1f}%, Valid acc: {:.1f}%.'\\\n",
    "                  .format(accuracy(batch_y_pred, batch_y),\n",
    "                          accuracy(tf_valid_y_pred.eval(), valid_y)))\n",
    "            \n",
    "    # final prediction for validation set\n",
    "    vaild_y_pred_before_restore = tf_valid_y_pred.eval()\n",
    "    \n",
    "    \n",
    "    # Save the variables to disk.\n",
    "    save_path = saver.save(sess, save_path)\n",
    "    print(\"Model saved in file: %s\" % save_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Although the performance can be further improved, as our goal is to train a simple model and deploy it, we will just leave it here and take a look where did the model make the mistake on validation set.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Show some mis-classified images"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get indices of mis-classified images in validation set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mislabeled_indices = []\n",
    "for idx, (i, j) in enumerate(zip(vaild_y_pred_before_restore.reshape(-1, 1), valid_y.reshape(-1, 1))):\n",
    "    prob, label = i[0], j[0]\n",
    "    label_pred = 1 if prob > 0.5 else 0\n",
    "    if label_pred != label: mislabeled_indices.append(idx)\n",
    "print('{}% of images are mis-classified in validation set.'\\\n",
    "      .format(len(mislabeled_indices) / valid_y.shape[0] * 100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "samples = np.random.choice(mislabeled_indices, 5)\n",
    "show_images_horizontally(valid_X[samples], valid_y[samples], figsize=(15, 10),\n",
    "                         lookup_label={0: 'Pred: Cat', 1: 'Pred: Dog'})\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Real time prediction simulation\n",
    "Upon now, we already trained a model that is ready to be deploy! Let's load the model we saved earlier and see whether we can generate the same prediction result on validation set using the loaded model.\n",
    "\n",
    "If there is any error in this part, try to restart kernel and run all the code again.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "meta_path = 'models/model.ckpt.meta'\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load the model and make prediction on validation set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Later, launch the model, use the saver to restore variables from disk, and\n",
    "# do some work with the model.\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    \n",
    "    # Restore variables from disk.\n",
    "    new_saver = tf.train.import_meta_graph(meta_path)\n",
    "    new_saver.restore(sess, save_path)\n",
    "    print(\"Model restored.\")\n",
    "    \n",
    "    #Now, access the op that you want to run. \n",
    "    graph = tf.get_default_graph()\n",
    "    tf_new_X = graph.get_tensor_by_name(\"tf_new_X:0\")\n",
    "    tf_new_y = graph.get_tensor_by_name(\"tf_new_y:0\")\n",
    "    tf_new_y_pred = graph.get_tensor_by_name(\"tf_new_y_pred:0\")\n",
    "\n",
    "    feed_dict = {\n",
    "        tf_new_X: valid_X[:1],\n",
    "        tf_new_y: valid_y[:1]\n",
    "    }\n",
    "\n",
    "    new_y_pred = sess.run(\n",
    "            [tf_new_y_pred], feed_dict=feed_dict)\n",
    "    \n",
    "    tf_valid_y_pred = graph.get_tensor_by_name(\"tf_valid_y_pred:0\")\n",
    "\n",
    "    vaild_y_pred_after_restore = tf_valid_y_pred.eval()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sanity check \n",
    "Compare prediction result on validation before/after model restoration to make sure we got the right model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, j in zip(vaild_y_pred_before_restore, vaild_y_pred_after_restore):\n",
    "    assert(i == j)\n",
    "print(\"Loaded model's prediction on validation is exactly the same as expected.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "gist": {
   "data": {
    "description": "cat_recognizer.ipynb",
    "public": true
   },
   "id": ""
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  },
  "toc": {
   "nav_menu": {
    "height": "265px",
    "width": "390px"
   },
   "number_sections": true,
   "sideBar": false,
   "skip_h1_title": false,
   "toc_cell": false,
   "toc_position": {
    "height": "248px",
    "left": "1018.23px",
    "right": "20px",
    "top": "120px",
    "width": "305px"
   },
   "toc_section_display": "none",
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "oldHeight": 297,
   "position": {
    "height": "319px",
    "left": "1091px",
    "right": "20px",
    "top": "132px",
    "width": "336px"
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "varInspector_section_display": "block",
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
